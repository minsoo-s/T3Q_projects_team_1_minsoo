{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "831ad166",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# 플랫폼 업로드를 쉽게하기 위한 로컬 개발 코드\n",
    "- T3Q.ai(T3Q.cep + T3Q.dl): 빅데이터/인공지능 통합 플랫폼\n",
    "- 플랫폼 업로드를 쉽게하기 위하여 로컬에서 아래의 코드(파일1)를 개발한다.\n",
    "- 파일 1(파일명): 1_local_platform_image_classification.ipynb\n",
    "\n",
    "### 전처리 객체 또는 학습모델 객체\n",
    "- 전처리 객체나 학습모델 객체는 meta_data 폴더 아래에 저장한다.\n",
    "\n",
    "### 데이터셋(학습 데이터/테스트 데이터)\n",
    "- 학습과 테스트에 사용되는 데이터를 나누어 관리한다.\n",
    "- 학습 데이터: dataset 폴더 아래에 저장하거나 dataset.zip 파일 형태로 저장한다.\n",
    "- 테스트 데이터: test_dataset 폴더 아래에 저장하거나 test_dataset.zip 파일 형태로 저장한다.\n",
    "\n",
    "### 로컬 개발 워크플로우(workflow)  \n",
    "- 로컬 개발 워크플로우를 다음의 4단계로 분리한다.\n",
    "\n",
    "1. 데이터셋 준비(Data Setup)\n",
    "- 로컬 저장소에서 전처리 및 학습에 필요한 학습 데이터셋을 준비한다.\n",
    "\n",
    "2. 데이터 전처리(Data Preprocessing)\n",
    "- 데이터셋의 분석 및 정규화(Normalization)등의 전처리를 수행한다.\n",
    "- 데이터를 모델 학습에 사용할 수 있도록 가공한다.\n",
    "- 추론과정에서 필요한 경우, 데이터 전처리에 사용된 객체를 meta_data 폴더 아래에 저장한다.\n",
    "\n",
    "3. 학습 모델 훈련(Train Model)\n",
    "- 데이터를 훈련에 사용할 수 있도록 가공한 뒤에 학습 모델을 구성한다. \n",
    "- 학습 모델을 준비된 데이터셋으로 훈련시킨다.\n",
    "- 정확도(Accuracy)나 손실(Loss)등 학습 모델의 성능을 검증한다.\n",
    "- 학습 모델의 성능 검증 후, 학습 모델을 배포한다.\n",
    "- 배포할 학습 모델을 meta_data 폴더 아래에 저장한다.\n",
    "\n",
    "4. 추론(Inference)\n",
    "- 저장된 전처리 객체나 학습 모델 객체를 준비한다.\n",
    "- 추론에 필요한 테스트 데이터셋을 준비한다.\n",
    "- 배포된 학습 모델을 통해 테스트 데이터에 대한 추론을 진행한다. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27499345-4512-444e-8c88-c8ad22a314fc",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# 인공지능 통합플랫폼(T3Q.ai) 프로세스를 이해하고 인공지능 쉽게 하기"
   ]
  },
  {
   "cell_type": "raw",
   "id": "234e102b",
   "metadata": {
    "pycharm": {
     "name": "#%% raw\n"
    }
   },
   "source": [
    "1. 머신러닝(Machine Learning)과 딥러닝(Deep Learning) 프로그래밍 패턴\n",
    "\n",
    "(1) 데이터셋 불러오기(Dataset Loading)\n",
    "(2) 데이터 전처리(Data Preprocessing)\n",
    "   - 데이터 정규화(Normalization)\n",
    "   - 학습과 테스트 데이터 분할(Train/Test Data Split) 등\n",
    "(3) 학습 모델 구성(Train Model Build)\n",
    "(4) 학습(Model Training)\n",
    "(5) 학습 모델 성능 검증(Model Performance Validation)\n",
    "(6) 학습 모델 저장(배포) 하기(Model Save)\n",
    "(7) 추론 데이터 전처리((Data Preprocessing)\n",
    "(8) 추론(Inference) 또는 예측(Prediction) \n",
    "(9) 추론 결과 데이터 후처리(Data Postprocessing) "
   ]
  },
  {
   "cell_type": "raw",
   "id": "f3590d00",
   "metadata": {
    "pycharm": {
     "name": "#%% raw\n"
    }
   },
   "source": [
    "2. 빅데이터/인공지능 통합 플랫폼[ T3Q.ai ]에서 딥러닝 프로그래밍 하고 인공지능 서비스 실시간 운용하기\n",
    " - 6개의 함수로 딥러닝 프로그래밍 하고 인공지능 서비스 실시간 운용하기\n",
    "\n",
    "(1) process_for_train(pm) 함수\n",
    " - 데이터셋 준비(Dataset Setup) \n",
    "   에 필요한 코드 작성\n",
    "\n",
    "(2) init_svc(im, rule) 함수\n",
    " - 전처리 객체 불러오기\n",
    "   에 필요한 코드 작성(생략 가능)\n",
    "\n",
    "(3) transform(df, params, batch_id) 함수\n",
    "- 추론 데이터 전처리((Data Preprocessing)\n",
    "  에 필요한 코드 작성(생략 가능)\n",
    "\n",
    "(4) train(tm) 함수 \n",
    " - 데이터셋 불러오기(Dataset Loading)\n",
    " - 데이터 전처리(Data Preprocessing)\n",
    " - 학습 모델 구성(Train Model Build)\n",
    " - 학습(Model Training)\n",
    " - 학습 모델 성능 검증(Model Performance Validation)\n",
    " - 전처리 객체 저장\n",
    " - 학습 모델 저장(배포) 하기\n",
    "   에 필요한 코드 작성\n",
    "\n",
    "(5) init_svc(im) 함수 \n",
    " - 전처리 객체 불러오기\n",
    " - 학습모델 객체 불러오기\n",
    "   에 필요한 코드 작성\n",
    "\n",
    "(6) inference(df, params, batch_id) 함수\n",
    " - 추론 데이터 전처리((Data Preprocessing)\n",
    " - 추론(Inference) 또는 예측(Prediction) \n",
    " - 추론 결과 데이터 후처리(Data Postprocessing) \n",
    "   에 필요한 코드 작성"
   ]
  },
  {
   "cell_type": "raw",
   "id": "c9372382",
   "metadata": {
    "pycharm": {
     "name": "#%% raw\n"
    }
   },
   "source": [
    "3. 전처리 모듈 관리, 학습 알고리즘 관리 함수 설명\n",
    "\n",
    "1) 프로젝트 설정/전처리모듈 관리 함수 \n",
    "\n",
    "def process_for_train(pm):\n",
    "    \"\"\"\n",
    "    (1) 입력: pm\n",
    "      # pm.source_path: 학습플랫폼/데이터셋 관리 메뉴에서 저장한 데이터를 불러오는 경로\n",
    "      # pm.target_path: 처리 완료된 데이터를 저장하는 경로\n",
    "    (2) 출력: None\n",
    "    (3) 설명: \n",
    "      # 데이터셋 관리 메뉴에서 저장한 데이터를 불러와서 필요한 처리를 수행\n",
    "      # 처리 완료된 데이터를 저장하는 기능, pm.target_path에 저장\n",
    "      # train(tm) 함수의 tm.train_data_path를 통해 데이터를 불러와서 전처리와 학습을 수행 \n",
    "    \"\"\"\n",
    "\n",
    "def init_svc(im, rule):\n",
    "    \"\"\"\n",
    "    (1) 입력: im, rule\n",
    "    (2) 출력: None\n",
    "    (3) 설명: \n",
    "      # process_for_train(pm) 함수에서 저장한 전처리 객체와 데이터에 적용된 룰(rule)을 불러오는 기능\n",
    "      # 전처리 객체, 룰(rule) 불러오기 기능 없이 처리\n",
    "    \"\"\"\n",
    "\n",
    "    return {}\n",
    "\n",
    "def transform(df, params, batch_id):\n",
    "    \"\"\"\n",
    "    (1) 입력: df, params, batch_id\n",
    "      # df: 추론모델관리와 추론API관리, 실시간 추론을 통해 전달되는 추론 입력 데이터(dataframe 형태)\n",
    "      # params: init_svc(im, rule) 함수의 리턴(return) 값을 params 변수로 전달\n",
    "    (2) 출력: df\n",
    "    (3) 설명: \n",
    "      # df(추론 입력 데이터)에 대한 전처리를 수행한 후 전처리 된 데이터를 inference(df, ...) 함수의 입력 df에 전달하는 기능\n",
    "      # df(추론 입력 데이터)를 전처리 없이 inference(df, params, batch_id) 함수의 입력 df에 리턴(return)\n",
    "    \"\"\"\n",
    "    \n",
    "    return df\n",
    "\n",
    "\n",
    "2) 프로젝트 설정/학습 알고리즘 관리 함수\n",
    "\n",
    "def train(tm):\n",
    "    \"\"\"\n",
    "    (1) 입력: tm\n",
    "      # tm.train_data_path: pm.target_path에 저장한 데이터를 불러오는 경로\n",
    "      # tm.model_path: 전처리 객체와 학습 모델 객체를 저장하는 경로\n",
    "    (2) 출력: None\n",
    "    (3) 설명: \n",
    "      # pm.target_path에 저장한 데이터를 tm.train_data_path를 통해 데이터를 불러오는 기능\n",
    "      # 데이터 전처리와 학습 모델을 구성하고 모델 학습을 수행\n",
    "      # 학습 모델의 성능을 검증하고 배포할 학습 모델을 저장\n",
    "      # 전처리 객체와 학습 모델 객체를 저장, tm.model_path에 저장\n",
    "      # init_svc(im) 함수의 im.model_path를 통해 전처리 객체와 학습 모델 객체를 준비\n",
    "    \"\"\"\n",
    "\n",
    "def init_svc(im):\n",
    "    \"\"\"\n",
    "    (1) 입력: im\n",
    "      # im.model_path: tm.model_path에 저장한 전처리 객체와 학습 모델 객체 등을 불러오는 경로\n",
    "    (2) 출력: 전처리 객체와 학습 모델 객체 등을 딕셔너리(dictionary) 형태로 리턴(return)\n",
    "    (3) 설명: \n",
    "      # tm.model_path에 저장한 전처리 객체와 학습 모델 객체 등을 불러오는 기능\n",
    "      # 전처리 객체, 룰(rule) 불러오기 기능 없이 처리\n",
    "      # 전처리 객체와 학습 모델 객체 등을 딕셔너리(dictionary) 형태로 리턴(return)\n",
    "      # 리턴(return) 값을 inference(df, params, batch_id) 함수의 입력 params 변수로 전달\n",
    "    \"\"\"\n",
    "\n",
    "    return { \"model\": model, \"param\": param }\n",
    "\n",
    "def inference(df, params, batch_id):\n",
    "    \"\"\"\n",
    "    (1) 입력: df, params, batch_id\n",
    "      # df: transform(df, params, batch_id)함수의 리턴(return) 값으로 전달된 df, 추론 입력 데이터(dataframe 형태)\n",
    "      # params  init_svc(im) 함수의 return 값을 params 변수로 전달\n",
    "        ## 학습 모델 객체 사용 예시       model=params['model']\n",
    "        ## 전처리(pca) 객체 사용 예시     pca=params['pca']\n",
    "    (2) 출력: 추론 결과를 딕셔너리(dictionary) 형태로 리턴(return)\n",
    "    (3) 설명: \n",
    "      # 전처리 객체를 사용하여 df(추론 입력 데이터)에 대한 전처리 수행\n",
    "      # 배포된 학습 모델(model)을 사용하여 df(추론 입력 데이터)에 추론(예측)을 수행\n",
    "      # 추론 결과를 딕셔너리(dictionary) 형태로 리턴(return)\n",
    "    \"\"\"\n",
    "    \n",
    "    return {\"inference\": result}"
   ]
  },
  {
   "cell_type": "raw",
   "id": "bbcaa728",
   "metadata": {
    "pycharm": {
     "name": "#%% raw\n"
    }
   },
   "source": [
    "4. 전처리 모듈 관리, 학습 알고리즘 관리 함수 설명(AI 훈민정음 프로젝트)\n",
    "\n",
    "1) 프로젝트 설정/전처리모듈 관리 함수(AI 훈민정음 프로젝트) \n",
    "\n",
    "import logging\n",
    "\n",
    "def process_for_train(pm):\n",
    "    \"\"\"\n",
    "    (1) 입력: pm\n",
    "      # pm.source_path: 학습플랫폼/데이터셋 관리 메뉴에서 저장한 데이터를 불러오는 경로\n",
    "      # pm.target_path: 처리 완료된 데이터를 저장하는 경로\n",
    "    (2) 출력: None\n",
    "    (3) 설명: \n",
    "      # 데이터셋 관리 메뉴에서 저장한 데이터를 불러와서 필요한 처리를 수행\n",
    "      # 처리 완료된 데이터를 저장하는 기능, pm.target_path에 저장\n",
    "      # train(tm) 함수의 tm.train_data_path를 통해 데이터를 불러와서 전처리와 학습을 수행 \n",
    "    (4) 추가 설명: \n",
    "      # 함수 구조는 원형대로 유지\n",
    "      # 실질적인 기능을 하는 함수를 서브모듈 함수(exec_process)로 정의하여 사용함\n",
    "      # 함수명                            서브함수명\n",
    "      # process_for_train(pm)          exec_process(pm) \n",
    "      # 함수의 정상적인 동작 체크를 위해 마지막 라인(the end line)에 로그 출력 수행\n",
    "    \"\"\"\n",
    "\n",
    "    exec_process(pm)\n",
    "    \n",
    "    logging.info('[hunmin log] the end line of the function [process_for_train]')\n",
    "\n",
    "def init_svc(im, rule):\n",
    "    \"\"\"\n",
    "    (1) 입력: im, rule\n",
    "    (2) 출력: None\n",
    "    (3) 설명: \n",
    "      # process_for_train(pm) 함수에서 저장한 전처리 객체와 데이터에 적용된 룰(rule)을 불러오는 기능\n",
    "      # 전처리 객체, 룰(rule) 불러오기 기능 없이 처리\n",
    "    \"\"\"\n",
    "\n",
    "    return {}\n",
    "\n",
    "def transform(df, params, batch_id):\n",
    "    \"\"\"\n",
    "    (1) 입력: df, params, batch_id\n",
    "      # df: 추론모델관리와 추론API관리, 실시간 추론을 통해 전달되는 추론 입력 데이터(dataframe 형태)\n",
    "      # params: init_svc(im, rule) 함수의 리턴(return) 값을 params 변수로 전달\n",
    "    (2) 출력: df\n",
    "    (3) 설명: \n",
    "      # df(추론 입력 데이터)에 대한 전처리를 수행한 후 전처리 된 데이터를 inference(df, ...) 함수의 입력 df에 전달하는 기능\n",
    "      # df(추론 입력 데이터)를 전처리 없이 inference(df, params, batch_id) 함수의 입력 df에 리턴(return)\n",
    "    (4) 추가 설명: \n",
    "      # 함수 구조는 원형대로 유지\n",
    "      # 함수의 정상적인 동작 체크를 위해 마지막 라인(the end line)에 로그 출력 수행            \n",
    "    \"\"\"\n",
    "    \n",
    "    logging.info('[hunmin log] the end line of the function [transform]')\n",
    "    \n",
    "    return df\n",
    "\n",
    "\n",
    "2) 프로젝트 설정/학습 알고리즘 관리 함수(AI 훈민정음 프로젝트)\n",
    "\n",
    "import logging\n",
    "\n",
    "def train(tm):\n",
    "    \"\"\"\n",
    "    (1) 입력: tm\n",
    "      # tm.train_data_path: pm.target_path에 저장한 데이터를 불러오는 경로\n",
    "      # tm.model_path: 전처리 객체와 학습 모델 객체를 저장하는 경로\n",
    "    (2) 출력: None\n",
    "    (3) 설명: \n",
    "      # pm.target_path에 저장한 데이터를 tm.train_data_path를 통해 데이터를 불러오는 기능\n",
    "      # 데이터 전처리와 학습 모델을 구성하고 모델 학습을 수행\n",
    "      # 학습 모델의 성능을 검증하고 배포할 학습 모델을 저장\n",
    "      # 전처리 객체와 학습 모델 객체를 저장, tm.model_path에 저장\n",
    "      # init_svc(im) 함수의 im.model_path를 통해 전처리 객체와 학습 모델 객체를 준비\n",
    "    (4) 추가 설명: \n",
    "      # 함수 구조는 원형대로 유지\n",
    "      # 실질적인 기능을 하는 함수를 서브모듈 함수(exec_train)로 정의하여 사용함\n",
    "      # 함수명                         서브함수명\n",
    "      # train(tm)                      exec_train(tm)\n",
    "      # 함수의 정상적인 동작 체크를 위해 마지막 라인(the end line)에 로그 출력 수행\n",
    "    \"\"\"\n",
    "\n",
    "    exec_train(tm)\n",
    "    \n",
    "    logging.info('[hunmin log] the end line of the function [train]')\n",
    "\n",
    "def init_svc(im):\n",
    "    \"\"\"\n",
    "    (1) 입력: im\n",
    "      # im.model_path: tm.model_path에 저장한 전처리 객체와 학습 모델 객체 등을 불러오는 경로\n",
    "    (2) 출력: 전처리 객체와 학습 모델 객체 등을 딕셔너리(dictionary) 형태로 리턴(return)\n",
    "    (3) 설명: \n",
    "      # tm.model_path에 저장한 전처리 객체와 학습 모델 객체 등을 불러오는 기능\n",
    "      # 전처리 객체, 룰(rule) 불러오기 기능 없이 처리\n",
    "      # 전처리 객체와 학습 모델 객체 등을 딕셔너리(dictionary) 형태로 리턴(return)\n",
    "      # 리턴(return) 값을 inference(df, params, batch_id) 함수의 입력 params 변수로 전달\n",
    "    (4) 추가 설명: \n",
    "      # 함수 구조는 원형대로 유지\n",
    "      # 실질적인 기능을 하는 함수를 서브모듈 함수(exec_init_svc)로 정의하여 사용함\n",
    "      # 함수명                            서브함수명\n",
    "      # init_svc(im)                      exec_init_svc(im)\n",
    "      # 함수의 정상적인 동작 체크를 위해 마지막 라인(the end line)에 로그 출력 수행      \n",
    "    \"\"\"\n",
    "\n",
    "    params = exec_init_svc(im)\n",
    "    \n",
    "    logging.info('[hunmin log] the end line of the function [init_svc]')\n",
    "    \n",
    "    return { **params }\n",
    "\n",
    "def inference(df, params, batch_id):\n",
    "    \"\"\"\n",
    "    (1) 입력: df, params, batch_id\n",
    "      # df: transform(df, params, batch_id)함수의 리턴(return) 값으로 전달된 df, 추론 입력 데이터(dataframe 형태)\n",
    "      # params  init_svc(im) 함수의 return 값을 params 변수로 전달\n",
    "        ## 학습 모델 객체 사용 예시       model=params['model']\n",
    "        ## 전처리 객체 사용 예시          pca=params['pre_model']\n",
    "    (2) 출력: 추론 결과를 딕셔너리(dictionary) 형태로 리턴(return)\n",
    "    (3) 설명: \n",
    "      # 전처리 객체를 사용하여 df(추론 입력 데이터)에 대한 전처리 수행\n",
    "      # 배포된 학습 모델(model)을 사용하여 df(추론 입력 데이터)에 추론(예측)을 수행\n",
    "      # 추론 결과를 딕셔너리(dictionary) 형태로 리턴(return)\n",
    "    (4) 추가 설명: \n",
    "      # 함수 구조는 원형대로 유지\n",
    "      # 실질적인 기능을 하는 함수를 서브모듈 함수(exec_inference)로 정의하여 사용함\n",
    "      # 함수명                                                     서브함수명\n",
    "      # inference(df, params, batch_id)                      exec_inference(df, params, batch_id)\n",
    "      # 함수의 정상적인 동작 체크를 위해 마지막 라인(the end line)에 로그 출력 수행            \n",
    "    \"\"\"\n",
    "    \n",
    "    result = exec_inference(df, params, batch_id)\n",
    "    \n",
    "    logging.info('[hunmin log] the end line of the function [inference]')\n",
    "\n",
    "    return { **result }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90d38753",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# 파일명: {data}_{method}_preprocess.py\n",
    "\n",
    "'''\n",
    "from {data}_{method}_preprocess_sub import exec_process\n",
    "'''\n",
    "import logging\n",
    "\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "\n",
    "# 학습 전 데이터 전처리\n",
    "def process_for_train(pm):\n",
    "    # pm : 플랫폼 사용에 필요한 객체 - 사용법은 exec_process에 있다.\n",
    "    \n",
    "    # 데이터 전처리 알고리즘 호출 - sub파일의 함수 사용\n",
    "    exec_process(pm)\n",
    "    \n",
    "    # return : return값은 없으나 전처리 완료된 데이터를 반드시 pm.target_path에 저장하여\n",
    "    #          학습 모델의 train함수의 tm.target_path로 불러와야 학습을 할 수 있다.\n",
    "    \n",
    "    \n",
    "# 데이텨 변환시 메모리에 standby 시켜놓을 데이터 반환\n",
    "def init_svc(im, rule):\n",
    "    # im : 플랫폼 사용에 필요한 객체\n",
    "    # rule : 전처리 규칙정보\n",
    "    \n",
    "    # im.meta_path : process_for_train의 pm.meta_path경로를 호출하여 학습때 사용한 전처리 모듈 및 메타 데이터를 불러온다.\n",
    "    \n",
    "    # return : dict형태로 반환하며 이는 transform의 params가 된다.\n",
    "    # ex) init_svc(im, rule): return {'meta_path' : im.meta_path}\n",
    "    #     transform(df, params, batch_id): meta_path = params['meta_path']\n",
    "    return {}\n",
    "\n",
    "# 추론 이전 데이터 변환\n",
    "def transform(df, params, batch_id):\n",
    "    # df => pd.DataFrame : 학습한 모델로 추론할 때 입력한 데이터\n",
    "    # params => Dict : init_svc의 반환값\n",
    "    # batch_id : 사용하지 않음\n",
    "    \n",
    "    # meta_path = params['meta_path'] : init_svc(im, rule)의 반환값중 'meta_path'를 불러온다.\n",
    "    # rule = params['rule'] : 전처리 규칙 불러오기\n",
    "    # use_cols = rule['source_column'] : 전처리 규칙중 사용한 컬럼명\n",
    "    # inner_df = df.loc[:, use_cols]\n",
    "    \n",
    "    # return : df 형태가 적절하며 이는 학습 모델에서 inference 함수의 df가 된다.\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60e75d89",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# 파일명: {data}_{method}_preprocess_sub.py\n",
    "\n",
    "def exec_process(pm):\n",
    "    # pm : 플랫폼 사용에 필요한 객체\n",
    "    \n",
    "    # pm.load_data(use_cols) : 원본 데이터를 DataFrame의 형태로 로딩. use_cols를 이용하여 특정 컬럼들만 지정할 수 있음.\n",
    "    # pm.save_data(df, index=True) : 전처리 완료된 데이터를 지정된 위치에 저장.\n",
    "    # pm.get_ids() : id 목록 조회\n",
    "    # pm.get_ids_by_class(label) : label값을 class로 갖는 id 목록 조회\n",
    "    # pm.get_y(ids) : id 목록에 해당하는 label 값 조회\n",
    "\n",
    "    # pm.rule : 룰 정보 (dictionary)\n",
    "    # pm.y_column : label 컬럼명\n",
    "    # pm.y_value : label 컬럼의 값목록\n",
    "    # pm.id_column : id 컬럼명\n",
    "    # pm.meta_path : 전처리 모듈 및 메타 데이터를 저장하기 위한 경로\n",
    "    # pm.source_path : 데이터 원본 경로    \n",
    "    # pm.target_path : 전처리 완료 데이터 경로\n",
    "    # pm.module_path : 실제 전처리 물리 모듈 경로\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8eb30c98",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# 파일명: {data}_{method}_train.py\n",
    "\n",
    "'''\n",
    "from {data}_{method}_train_sub import exec_train, exec_init_svc, exec_inference\n",
    "'''\n",
    "import logging\n",
    "\n",
    "# 모델 학습\n",
    "def train(tm):\n",
    "    # tm : 플랫폼 사용에 필요한 객체\n",
    "    \n",
    "    # 학습 알고리즘 호출 - sub파일의 함수 사용\n",
    "    exec_train(tm)\n",
    "\n",
    "\n",
    "# 데이터 추론시 메모리에 standby 시켜놓을 데이터 반환\n",
    "def init_svc(im):\n",
    "    # im : 플랫폼 사용에 필요한 객체\n",
    "    \n",
    "    # 초기화 함수 호출 - sub파일의 함수 사용\n",
    "    params = exec_init_svc(im)\n",
    "    \n",
    "    return { **params }\n",
    "\n",
    "\n",
    "# 추론\n",
    "def inference(df, params, batch_id):\n",
    "    # df => pd.DataFrame : process.py에서 transform의 반환값\n",
    "    # params => Dict : init_svc(im)의 반환값\n",
    "    # batch_id : 사용하지 않음\n",
    "    \n",
    "    # 추론 함수 호출 - sub파일의 함수 사용\n",
    "    result = exec_inference(df, params, batch_id)\n",
    "    \n",
    "    return { **result }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "162f216b",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# 파일명: {data}_{method}_train_sub.py\n",
    "\n",
    "import logging\n",
    "\n",
    "def exec_train(tm):\n",
    "    # tm : 플랫폼 사용에 필요한 객체\n",
    "    \n",
    "    # tm.features.get('y_value') : labels\n",
    "    \n",
    "    # tm.load_data_for_cnn() : cnn 데이터\n",
    "    # tm.load_data_for_all() : 기타 데이터\n",
    "    # ex) (train_id, train_x, train_y), (test_id, test_x, test_y) = tm.load_data_for_cnn()\n",
    "    \n",
    "    \n",
    "    # tm.param_info[\"{param_name}\"] : 학습 알고리즘에서 사용되는 파라미터 값으로, 플랫폼 내에서 정의됨\n",
    "    #                                 학습 알고리즘 코드에 미리 정의해두어도 되지만 학습마다 파라미터를 달리하고싶을 때 용이함\n",
    "    \n",
    "    # tm.param_info[\"nn_type\"] : NN 유형\n",
    "    # tm.param_info[\"init_method\"] : 초기화 방법\n",
    "    # tm.param_info[\"opt_method\"] : 최적화 방법\n",
    "    # tm.param_info[\"learning_rate\"] : Learning Rate\n",
    "    # tm.param_info[\"dropout_ratio\"] : Dropout Ratio\n",
    "    # tm.param_info[\"random_seed\"] : 랜덤 seed\n",
    "    # tm.param_info[\"autosave_p\"] : 자동저장 주기\n",
    "    # tm.param_info[\"epoch\"] : 학습수행횟수\n",
    "    # tm.param_info[\"batch_size\"] : 배치 사이즈\n",
    "    \n",
    "    # ex)\n",
    "    # batch_size = int(tm.param_info['batch_size'])\n",
    "    # epochs = int(tm.param_info['epoch'])\n",
    "    \n",
    "    \n",
    "    # 학습 결과 표출 함수화\n",
    "    '''\n",
    "    plot_metrics(tm, history, model, X_test, Y_test)\n",
    "    '''\n",
    "    \n",
    "    # tm.model_path : init_svc로 전달되는 경로로 im.model_path와 동일함\n",
    "    \n",
    "    # return : return값은 없으나 tm.model_path에 모델을 저장해야 추론에 모델을 사용할 수 있음\n",
    "    # ex) model.save(os.path.join(tm.model_path, 'model.h5'))\n",
    "\n",
    "\n",
    "\n",
    "def exec_init_svc(im):\n",
    "    # im : 플랫폼 사용에 필요한 객체\n",
    "    \n",
    "    # im.features.get('y_value') : labels\n",
    "    # im.param_info : params\n",
    "    # im.nn_info : nn_info\n",
    "    # im.model_path : train(tm)에서 tm.model_path와 동일한 경로를 호춯하여 학습된 모델 및 메타데이터를 불러온다.\n",
    "    \n",
    "    \n",
    "    # return : dict형태로 반환하며 이는 inference함수의 params가 된다.\n",
    "    # ex) model = load_model(os.path.join(im.model_path, 'model.h5'))\n",
    "    #     return { 'model': model }\n",
    "    \n",
    "    return { 'model': model }\n",
    "\n",
    "\n",
    "\n",
    "def exec_inference(df, params, batch_id):\n",
    "    # df => pd.DataFrame : 학습한 모델로 추론할 때 입력한 데이터\n",
    "    # params => Dict : init_svc의 반환값\n",
    "    # batch_id : 사용하지 않음\n",
    "    \n",
    "    # model = params['model'] : init_svc(im)의 반환값중 'model'을 불러온다.\n",
    "\n",
    "    # return : JSON형식으로 변환이 가능한 Dict로 반환되며\n",
    "    #          실시간 추론 API의 반환값이 된다.\n",
    "    # ex) return {'inference' : model.predict(df.iloc[0, 0])}\n",
    "    return {'inference' : model.predict(df.iloc[0, 0])}\n",
    "\n",
    "\n",
    "# 시각화\n",
    "# 굳이 실행하지 않더라도 플랫폼에 오류는 없으나 학습결과를 확인하기 위해 필요\n",
    "# 모델 성능 및 학습과정을 계산하고 저장하여 시각화\n",
    "def plot_metrics(tm, history, model, x_test, y_test):\n",
    "    from sklearn.metrics import confusion_matrix\n",
    "    \n",
    "    accuracy_list = history.history['accuracy']\n",
    "    loss_list = history.history['loss']\n",
    "    \n",
    "    for step, (acc, loss) in enumerate(zip(accuracy_list, loss_list)):\n",
    "        metric={}\n",
    "        metric['accuracy'] = acc\n",
    "        metric['loss'] = loss\n",
    "        metric['step'] = step\n",
    "        tm.save_stat_metrics(metric)\n",
    "\n",
    "    predict_y = np.argmax(model.predict(x_test), axis = 1).tolist()\n",
    "    actual_y = np.argmax(y_test, axis = 1).tolist()\n",
    "    \n",
    "    eval_results={}\n",
    "    eval_results['predict_y'] = predict_y\n",
    "    eval_results['actual_y'] = actual_y\n",
    "    eval_results['accuracy'] = history.history['val_accuracy'][-1]\n",
    "    eval_results['loss'] = history.history['val_loss'][-1]\n",
    "\n",
    "    # calculate_confusion_matrix(eval_results)\n",
    "    eval_results['confusion_matrix'] = confusion_matrix(actual_y, predict_y).tolist()\n",
    "    tm.save_result_metrics(eval_results)\n",
    "    logging.info('[user log] accuracy and loss curve plot for platform')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93ca7be6",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# PM 클래스: pm 객체\n",
    "class PM:\n",
    "    def __init__(self):\n",
    "        self.source_path = './'\n",
    "        self.target_path = './meta_data'\n",
    "\n",
    "# TM 클래스: tm 객체\n",
    "class TM:\n",
    "    param_info = {}\n",
    "    def __init__(self):\n",
    "        self.train_data_path = './meta_data'\n",
    "        self.model_path = './meta_data'\n",
    "        # 사용자 param 사용시 입력\n",
    "        self.param_info['batch_size'] = 10\n",
    "        self.param_info['epoch'] = 20\n",
    "\n",
    "# IM 클래스: im 객체\n",
    "class IM:\n",
    "    def __init__(self):\n",
    "        self.model_path = './meta_data'\n",
    "\n",
    "\n",
    "# pm 객체\n",
    "pm = PM()\n",
    "print('pm.source_path:', pm.source_path)\n",
    "print('pm.target_path: ', pm.target_path)\n",
    "\n",
    "# tm 객체\n",
    "tm = TM()\n",
    "print('tm.train_data_path: ', tm.train_data_path)\n",
    "print('tm.model_path: ', tm.model_path)\n",
    "print('tm.param_info[\\'batch_size\\']: ', tm.param_info['batch_size'])\n",
    "print('tm.param_info[\\'epoch\\']: ', tm.param_info['epoch'])\n",
    "\n",
    "# im 객체\n",
    "im = IM()\n",
    "print('im.model_path: ', im.model_path)\n",
    "\n",
    "# inferecne(df, params, batch_id) 함수 입력\n",
    "params = {}\n",
    "batch_id = 0\n",
    "\n",
    "import io\n",
    "import pandas as pd\n",
    "\n",
    "# base64 encoded image\n",
    "# jpg파일을 base64 format으로 encoding한 데이터입니다.\n",
    "data = [['iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAIAAAD9b0jDAAAAAXNSR0IArs4c6QAAAARnQU1BAACxjwv8YQUAAAAJcEhZcwAADsMAAA7DAcdvqGQAAACySURBVEhL7ZLRDoAgCEWt//9nc8EIEepStvXQeWkyPEKw1FrLbFb+TuWXzichXXb4cAokJR0tH+JFK21G8V6CSqlApMxGelBIsVBHeOOEzZYGdRzpussfL7eIazHPa0wrx0GMdBSiuMbkdINyb5og0gRL3dTbcPtNOpYZveQ2pA1n0hTakF5+hA9Lzd87pNFYLhkvsvT2lMhorndluxkRUuCYbzcp9ROi55+up8sLK1XKBj1wbx3DelAOAAAAAElFTkSuQmCC']]\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "print('df: ', df)\n",
    "print('df.dtypes:', df.dtypes)\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "934406ce",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# 플랫폼 내부 수행 순서"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abe76d94",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "process_for_train(pm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ec16726",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "train(tm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab6768ef",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# params = init_svc(im, rule)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ad3e43c",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "transform(df, params, batch_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d336e4c",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "params = init_svc(im)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d16f8b5f",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "inference(df, params, batch_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3963cbf4",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "EV_PY38_YOLOv5",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13 (default, Oct 19 2022, 22:38:03) [MSC v.1916 64 bit (AMD64)]"
  },
  "vscode": {
   "interpreter": {
    "hash": "bc6472e1bd2b63c7ab4bb27b41d9492121ae2cc6eae589bc296637b602f4a6f4"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
